{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdm9oj6wFe56"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install langchain-community langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langgraph"
      ],
      "metadata": {
        "id": "sTntt2xUNQM2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f62b022-e542-4628-c9da-8c9f40154370"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
            "Successfully installed langgraph-0.4.9 langgraph-checkpoint-2.1.0 langgraph-prebuilt-0.2.2 langgraph-sdk-0.1.70 ormsgpack-1.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain langchain-openai"
      ],
      "metadata": {
        "id": "VdGDi_UwPIMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import MessagesPlaceholder\n"
      ],
      "metadata": {
        "id": "2CqvvPi0GCQ0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = 'OPENAI_API_KEY'\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = 'LANGCHAIN_API_KEY'\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"Langgraph_1\"\n",
        "os.environ[\"LANGSMITH_ENDPOINT\"] = \"https://api.smith.langchain.com\""
      ],
      "metadata": {
        "id": "MR5WEHUHPsTH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generation_prompt = ChatPromptTemplate.from_messages([\n",
        "    \"system\",\"You are a twitter influencer who writes knowledgable tweets on a topic. In case you get critiqued, you refine and rewrite your tweets\",\n",
        "    MessagesPlaceholder(variable_name=\"messages\")\n",
        "])"
      ],
      "metadata": {
        "id": "wMhqcLlWHJlt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reflection_prompt = ChatPromptTemplate.from_messages([\n",
        "    \"system\",\"You are a twitter influencer who critiques tweets and provide detailed recommendations on how to refine a tweet \",\n",
        "    MessagesPlaceholder(variable_name=\"messages\")\n",
        "])"
      ],
      "metadata": {
        "id": "liExm627H86W"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI()\n",
        "\n",
        "generation_chain = generation_prompt|llm\n",
        "reflection_chain = reflection_prompt|llm\n"
      ],
      "metadata": {
        "id": "gp55W__kIfw_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc32a28a-3a4a-4cd0-8bfa-46bdd34aabd6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-10-2596449446.py:1: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  llm = ChatOpenAI()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Sequence\n",
        "from langchain_core.messages import BaseMessage, HumanMessage\n",
        "from langgraph.graph import END, MessageGraph\n"
      ],
      "metadata": {
        "id": "LcWdVHQ3NCJl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "REFLECT = \"reflect\"\n",
        "GENERATE = \"generate\"\n",
        "graph = MessageGraph()"
      ],
      "metadata": {
        "id": "9ENVNlDDNJde"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_node(state):\n",
        "    return generation_chain.invoke({\n",
        "        \"messages\": state\n",
        "    })\n",
        "\n",
        "\n",
        "def reflect_node(messages):\n",
        "    response = reflection_chain.invoke({\n",
        "        \"messages\": messages\n",
        "    })\n",
        "    return [HumanMessage(content=response.content)]\n",
        "\n",
        "\n",
        "graph.add_node(GENERATE, generate_node)\n",
        "graph.add_node(REFLECT, reflect_node)\n",
        "graph.set_entry_point(GENERATE)\n",
        "\n",
        "\n",
        "def should_continue(state):\n",
        "    if (len(state) > 6):\n",
        "        return END\n",
        "    return REFLECT\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Thhgh7-bNhH4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph.add_conditional_edges(GENERATE, should_continue)\n",
        "graph.add_edge(REFLECT, GENERATE)\n",
        "\n",
        "app = graph.compile()\n",
        "\n",
        "\n",
        "print(app.get_graph().draw_mermaid())\n",
        "#app.get_graph().print_ascii()\n",
        "\n",
        "response = app.invoke(HumanMessage(content=\"What is going to be the next best non-techincal role in the AI world\"))\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyHKrTh3NzGs",
        "outputId": "7be217fc-1fef-4664-ab22-ba8cf40c54a2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n",
            "config:\n",
            "  flowchart:\n",
            "    curve: linear\n",
            "---\n",
            "graph TD;\n",
            "\t__start__(<p>__start__</p>)\n",
            "\tgenerate(generate)\n",
            "\treflect(reflect)\n",
            "\t__end__(<p>__end__</p>)\n",
            "\t__start__ --> generate;\n",
            "\tgenerate --> __end__;\n",
            "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
            "\tclassDef first fill-opacity:0\n",
            "\tclassDef last fill:#bfb6fc\n",
            "\n",
            "[HumanMessage(content='What is going to be the next best non-techincal role in the AI world', additional_kwargs={}, response_metadata={}, id='4e1c18e5-12af-40a2-9232-0e282f060aa9'), AIMessage(content='The next best non-technical role in the AI world is likely to be a data ethics or AI ethics specialist. As AI technology continues to advance rapidly, there is a growing need for professionals who can ensure that AI systems are developed and used ethically and responsibly. Data ethics specialists play a crucial role in addressing issues such as bias, privacy, and transparency in AI systems, and their expertise will be in high demand as the field of AI continues to evolve. #AI #DataEthics #EthicalAI', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 102, 'prompt_tokens': 63, 'total_tokens': 165, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--4e916ad7-51dd-4db9-bfe8-b543892b4579-0'), HumanMessage(content='Recommendation: \\n1. Specify the audience: It would be helpful to specify who you are addressing in your tweet. Are you talking to individuals looking to enter the field of AI or employers looking to hire in this area? This will make your message more targeted and relevant.\\n2. Provide examples or insights: Consider including examples or insights about the importance of data ethics in the AI field to strengthen your argument and provide more value to your audience.\\n3. Use relevant hashtags: Utilize relevant hashtags such as #AI, #DataEthics, and #EthicalAI to increase the visibility of your tweet and attract a larger audience interested in this topic. \\n\\nRefined tweet: \"Data ethics specialists are set to play a vital role in the evolving field of AI, ensuring that AI systems are developed and used ethically. Their expertise in addressing bias, privacy, and transparency will be in high demand. #AI #DataEthics #EthicalAI\"', additional_kwargs={}, response_metadata={}, id='85851ab0-19f0-47cb-8b19-cf3762227c90'), AIMessage(content='\"Data ethics specialists are set to play a vital role in the evolving field of AI, ensuring that AI systems are developed and used ethically. Their expertise in addressing bias, privacy, and transparency will be in high demand. #AI #DataEthics #EthicalAI\"', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 56, 'prompt_tokens': 365, 'total_tokens': 421, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--e60c49c5-2f07-41c8-8dd9-a05d824a7819-0'), HumanMessage(content='Great! Let me know if you need any more assistance with refining your tweets or if you have any other questions. #TwitterInfluencer #TweetCritique', additional_kwargs={}, response_metadata={}, id='154e574b-fe3e-499f-aa4b-30185bd36f31'), AIMessage(content=\"Thank you for your offer! I'll reach out if I need further assistance with refining my tweets or if I have any other questions. Your feedback has been very helpful. #TwitterInfluencer #TweetCritique\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 461, 'total_tokens': 504, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--79116d8f-80fb-41de-96e6-47b9bffa3701-0'), HumanMessage(content=\"Thank you for your offer! I'll reach out if I need further assistance with refining my tweets or if I have any other questions. Your feedback has been very helpful. #TwitterInfluencer #TweetCritique\", additional_kwargs={}, response_metadata={}, id='c85a043a-1c89-4e5b-a804-e50bc2ac8322'), AIMessage(content=\"Great job with your refined tweet! It's concise, informative, and engaging. Keep up the good work with your Twitter influencer content, and feel free to reach out if you need more assistance or have any questions in the future. #TwitterInfluencer #TweetCritique\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 56, 'prompt_tokens': 555, 'total_tokens': 611, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--2fed7b64-ce8f-4654-a5b1-a6699a979922-0')]\n"
          ]
        }
      ]
    }
  ]
}